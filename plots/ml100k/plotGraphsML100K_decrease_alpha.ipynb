{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Split users:   5%|▌         | 21/408 [00:00<00:01, 208.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: random seed is None, default class seed (42) will be used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/10000 [00:00<29:51,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[it 0] weight norms, users: 72.81585693359375, items: 96.86475372314453\n",
      "[it 0] metrics (emb_loss, net_loss, reg, target): (0.76785225, 0.69265568, 16.98176, 0.69435388)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1027/10000 [00:07<00:59, 149.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:1000\n",
      "alpha:0.9\n",
      "beta:0.1\n",
      "[it 1000] weight norms, users: 73.4916763305664, items: 97.24102020263672\n",
      "[it 1000] metrics (emb_loss, net_loss, reg, target): (0.7375989, 0.46065721, 17.529514, 0.46241015)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2023/10000 [00:13<00:53, 149.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:2000\n",
      "alpha:0.8\n",
      "beta:0.2\n",
      "[it 2000] weight norms, users: 74.3607406616211, items: 97.95825958251953\n",
      "[it 2000] metrics (emb_loss, net_loss, reg, target): (0.71302599, 0.40455431, 17.975195, 0.40635183)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3032/10000 [00:21<00:46, 151.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:3000\n",
      "alpha:0.7000000000000001\n",
      "beta:0.30000000000000004\n",
      "[it 3000] weight norms, users: 74.95774841308594, items: 98.79998016357422\n",
      "[it 3000] metrics (emb_loss, net_loss, reg, target): (0.73463649, 0.33779424, 18.561602, 0.33965039)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4020/10000 [00:28<00:40, 147.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:4000\n",
      "alpha:0.6000000000000001\n",
      "beta:0.4\n",
      "[it 4000] weight norms, users: 75.41100311279297, items: 99.59468078613281\n",
      "[it 4000] metrics (emb_loss, net_loss, reg, target): (0.75449377, 0.29046127, 18.853888, 0.29234666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5029/10000 [00:34<00:34, 144.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:5000\n",
      "alpha:0.5000000000000001\n",
      "beta:0.5\n",
      "[it 5000] weight norms, users: 75.79373168945312, items: 100.34326171875\n",
      "[it 5000] metrics (emb_loss, net_loss, reg, target): (0.78779411, 0.27108866, 19.20962, 0.27300963)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6029/10000 [00:43<00:25, 153.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:6000\n",
      "alpha:0.40000000000000013\n",
      "beta:0.6\n",
      "[it 6000] weight norms, users: 76.1424560546875, items: 101.03257751464844\n",
      "[it 6000] metrics (emb_loss, net_loss, reg, target): (0.80028605, 0.22006002, 19.671417, 0.22202717)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7022/10000 [00:50<00:20, 142.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:7000\n",
      "alpha:0.30000000000000016\n",
      "beta:0.7\n",
      "[it 7000] weight norms, users: 76.46220397949219, items: 101.67634582519531\n",
      "[it 7000] metrics (emb_loss, net_loss, reg, target): (0.75229669, 0.21339193, 19.786814, 0.21537061)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8024/10000 [00:59<00:13, 148.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:8000\n",
      "alpha:0.20000000000000015\n",
      "beta:0.7999999999999999\n",
      "[it 8000] weight norms, users: 76.76631927490234, items: 102.27267456054688\n",
      "[it 8000] metrics (emb_loss, net_loss, reg, target): (0.79241133, 0.2155387, 19.784639, 0.21751715)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9032/10000 [01:06<00:06, 158.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:9000\n",
      "alpha:0.10000000000000014\n",
      "beta:0.8999999999999999\n",
      "[it 9000] weight norms, users: 77.02434539794922, items: 102.82274627685547\n",
      "[it 9000] metrics (emb_loss, net_loss, reg, target): (0.83365059, 0.20401697, 20.114483, 0.20602842)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:12<00:00, 137.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import letor_metrics\n",
    "import pyximport\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "pyximport.install()\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "raw_data_train = np.loadtxt('/data/recnet_draft/ml100k/train_all_raw.csv', skiprows = 1, delimiter=',')\n",
    "raw_data_test = np.loadtxt('/data/recnet_draft/ml100k/test_all_raw.csv', skiprows = 1, delimiter=',')\n",
    "raw_data = np.concatenate((raw_data_train, raw_data_test))\n",
    "from dataset_tt_static import TripletsDataset\n",
    "\n",
    "ds = TripletsDataset(raw_data_train, raw_data_test, threshold_user=60, rnd_seed=42)\n",
    "ds.train_test_split()\n",
    "\n",
    "ds.init_cached_random()\n",
    "import tensorflow as tf\n",
    "import bprnn_ml100k_param_tune_all\n",
    "import imp\n",
    "\n",
    "N_USERS = int(max(raw_data[:, 0])) + 1\n",
    "N_ITEMS = int(max(raw_data[:, 1])) + 1\n",
    "N_EMBEDDINGS = 17\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "imp.reload(bprnn_ml100k_param_tune_all)\n",
    "\n",
    "#%%\n",
    "def inner_network(user_emb, item_emb):\n",
    "    joined_input = tf.concat([user_emb, item_emb], 1)\n",
    "    net = slim.fully_connected(inputs=joined_input, num_outputs=32, activation_fn=tf.nn.relu)\n",
    "#     net = slim.fully_connected(inputs=joined_input, num_outputs=64, activation_fn=tf.nn.relu)\n",
    "#     net = slim.dro\n",
    "    net = slim.fully_connected(inputs=net, num_outputs=1, activation_fn=None)\n",
    "    return net\n",
    "\n",
    "model = bprnn_ml100k_param_tune_all.BPR_NN(N_USERS, N_ITEMS, N_EMBEDDINGS, alpha=1, beta=0, alpha_reg=0.0001, inner_net=inner_network)\n",
    "model.build_graph()\n",
    "model.initialize_session()\n",
    "\n",
    "losses = []\n",
    "batch_size = 512\n",
    "for n_batches, cur_optim in [(10000, model.trainer_3)]:\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        if i%1000==0 and i/1000 >= 1:\n",
    "            model.alpha = model.alpha - 0.1\n",
    "            model.beta = model.beta + 0.1\n",
    "            print('batch number:'+str(i))\n",
    "            print('alpha:'+ str(model.alpha))\n",
    "            print('beta:'+ str(model.beta))\n",
    "        batch = ds.sample_train_batch(n_samples=batch_size)\n",
    "        fd = {\n",
    "            model.user_ids:  batch['users'], \n",
    "            model.left_ids:  batch['left_items'],\n",
    "            model.right_ids: batch['right_items'],\n",
    "            model.target_y:  batch['y'],\n",
    "        }\n",
    "        el, nl, reg, t, _ = model.session.run(\n",
    "            [model.embedding_loss, model.net_loss, model.regularization, model.target, cur_optim], \n",
    "            feed_dict=fd\n",
    "        )\n",
    "        losses.append((el, nl, reg, t))\n",
    "        if i%1000==0:\n",
    "            user_norm = np.linalg.norm(model.weights_u)\n",
    "            item_norm = np.linalg.norm(model.weights_i)\n",
    "            print('[it {}] weight norms, users: {}, items: {}'.format(i, user_norm, item_norm))\n",
    "            print('[it {}] metrics (emb_loss, net_loss, reg, target): {}'.format(i, losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction: 100%|██████████| 408/408 [00:00<00:00, 3042.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8396538878217249, 0.42264158484677827, 0.70150996472324456, nan, 1.0, 0.94039623903753067, 0.61776399916124758, 1.0, 0.5, 0.85034490553475461, 1.0, 0.93637921180104833, 0.45560514958746035, 0.38685280723454163, 0.87060868542699299, 0.93056877806322291, 0.63092975357145753, 0.91972078914818756, 0.77209115442140641, 0.66650486981001134, 0.94690242952597448, 0.72641273023066366, 0.73757284928660216, 0.85999191954790177, 0.48247555939075504, 0.96746798348916929, 0.50148397124678246, nan, 1.0, 0.92020546143755177, 0.36334128725957199, 0.70263051638546459, 1.0, 0.84860265890399011, 1.0, 0.87381008988013231, 1.0, 0.9216017310213247, 0.69759616950614933, 0.58679458467691459, 1.0, 0.99332229988146181, 1.0, 0.7702043899253147, nan, 0.97992148014470837, nan, nan, 0.63092975357145753, 0.56191072411498288, 0.77990823370191997, 0.55226547738705301, 0.88995411685096004, 1.0, 0.43067655807339306, 0.62405052000383787, 1.0, 0.87721531533804931, 0.63092975357145753, 1.0, 0.88397641507283109, nan, nan, 1.0, 0.90602543553468229, 0.84542566042160183, 1.0, 1.0, 0.90682503796496661, 0.44927383782962327, 1.0, 0.0, 1.0, 1.0, 1.0, 0.78591628563015836, 0.98289208195668787, 0.9216017310213247, nan, nan, 0.5, 0.93056877806322291, 1.0, 1.0, nan, 0.73282862047779107, 0.88995411685096004, 1.0, 0.62405052000383787, 0.91972078914818756]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "export_basename = '/data/recnet_draft/ml100k/dec_alpha/vectors/'\n",
    "export_pred = open(export_basename + 'pr_ml100k_10', 'w')\n",
    "export_true = open(export_basename + 'gt_ml100k_10', 'w')\n",
    "\n",
    "ndcg_vals = []\n",
    "for u in tqdm(ds.data_keys, desc='Prediction', leave=True):\n",
    "    # if not u in ds.test:\n",
    "    if not u in ds.test or not ds.test[u]:\n",
    "        continue\n",
    "    response = np.zeros(len(ds.test[u]))\n",
    "    fd = {\n",
    "            model.user_ids:  (np.ones(len(ds.test[u]))*u).astype(np.int32), \n",
    "            model.left_ids:  np.array([i for (i, r) in ds.test[u]]).astype(np.int32),\n",
    "        }\n",
    "    response += model.session.run(model.embedding_left, feed_dict=fd)[:, 0]\n",
    "    response += model.session.run(model.left_output, feed_dict=fd)[:, 0]\n",
    "\n",
    "    # make relevances\n",
    "    relevances = np.array([r for (i, r) in ds.test[u]])\n",
    "    items = np.array([i for (i, r) in ds.test[u]])  # it's already sorted by true relevance\n",
    "    itemsGroundTruth = np.array([i for (i,r) in ds.test[u] if r == 1])\n",
    "    predicted_ranking = np.argsort(-response)\n",
    "\n",
    "    # write down predictions\n",
    "    export_pred.write(' '.join(map(str, [u] + list(items[predicted_ranking]))) + '\\n')\n",
    "    export_true.write(' '.join(map(str, [u] + list(itemsGroundTruth))) + '\\n')\n",
    "\n",
    "    # calc score\n",
    "    gain = letor_metrics.ndcg_from_ranking(relevances, predicted_ranking, 10)\n",
    "    ndcg_vals.append(gain)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "print(ndcg_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ints = [100, 500, 1000, 2000, 5000, 10000]\n",
    "pos = 1\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2)\n",
    "#ax[-1, -1].axis('off')\n",
    "\n",
    "for int in ints:\n",
    "    axis = plt.subplot(3, 2, pos)\n",
    "    axis.plot([x[0] for x in losses[:int]], c='b', label='embedding_loss')\n",
    "    grid()\n",
    "    legend()\n",
    "    xlabel('n_batches')\n",
    "    ylabel('embedding loss')\n",
    "    yscale('log')\n",
    "    draw()\n",
    "    show(block=False)\n",
    "    pos = pos + 1\n",
    "    fig.savefig('/home/sumit/recnet_draft/plots/ml100k/embedding_loss_dec_alpha.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ints = [100, 500, 1000, 2000, 5000, 10000]\n",
    "pos = 1\n",
    "fig, ax = plt.subplots(nrows=3, ncols=2)\n",
    "\n",
    "for int in ints:\n",
    "    axis = plt.subplot(3, 2, pos)\n",
    "    axis.plot([x[1] for x in losses[:int]], c='m', label='ranking_loss')\n",
    "    grid()\n",
    "    legend()\n",
    "    xlabel('n_batches')\n",
    "    ylabel('logloss')\n",
    "    yscale('log')\n",
    "    draw()\n",
    "    show(block=False)\n",
    "    pos = pos + 1\n",
    "    fig.savefig('/home/sumit/recnet_draft/plots/ml100k/ranking_loss_dec_alpha.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ints = [100, 500, 1000, 2000, 5000, 10000]\n",
    "pos = 1\n",
    "fig, ax = plt.subplots(nrows=3, ncols=2)\n",
    "for int in ints:\n",
    "    axis = plt.subplot(3, 2, pos)\n",
    "    axis.plot([x[3] for x in losses[: int]], c='g', label='target')\n",
    "    grid()\n",
    "    legend()\n",
    "    xlabel('n_batches')\n",
    "    ylabel('recnet loss')\n",
    "    #yscale('log')\n",
    "    draw()\n",
    "    show(block=False)\n",
    "    pos = pos + 1\n",
    "    fig.savefig('/home/sumit/recnet_draft/plots/ml100k/target_loss_dec_alpha')\n",
    "plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
