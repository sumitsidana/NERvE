{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Split users:   9%|▉         | 38/408 [00:00<00:02, 171.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: random seed is None, default class seed (42) will be used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/10000 [00:00<20:42,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[it 0] weight norms, users: 24.89217185974121, items: 33.103614807128906\n",
      "[it 0] metrics (emb_loss, net_loss, reg, target): (0.70632982, 0.69421673, 1.9343712, 0.71600169)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1018/10000 [00:06<00:56, 158.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:1000\n",
      "alpha:0.1\n",
      "beta:0.9\n",
      "[it 1000] weight norms, users: 27.076431274414062, items: 32.525390625\n",
      "[it 1000] metrics (emb_loss, net_loss, reg, target): (0.58758307, 0.68635154, 2.5332975, 0.60024953)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2026/10000 [00:13<00:55, 144.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:2000\n",
      "alpha:0.2\n",
      "beta:0.8\n",
      "[it 2000] weight norms, users: 31.33741569519043, items: 34.590843200683594\n",
      "[it 2000] metrics (emb_loss, net_loss, reg, target): (0.52846777, 0.6811502, 3.8200161, 0.54756784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3016/10000 [00:21<00:49, 142.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:3000\n",
      "alpha:0.30000000000000004\n",
      "beta:0.7000000000000001\n",
      "[it 3000] weight norms, users: 33.940399169921875, items: 36.65824890136719\n",
      "[it 3000] metrics (emb_loss, net_loss, reg, target): (0.48384041, 0.68359667, 4.3144565, 0.5054127)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4015/10000 [00:27<00:41, 142.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:4000\n",
      "alpha:0.4\n",
      "beta:0.6000000000000001\n",
      "[it 4000] weight norms, users: 35.54875564575195, items: 38.38079833984375\n",
      "[it 4000] metrics (emb_loss, net_loss, reg, target): (0.46206757, 0.68093055, 4.6838017, 0.48548657)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5023/10000 [00:34<00:34, 144.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:5000\n",
      "alpha:0.5\n",
      "beta:0.5000000000000001\n",
      "[it 5000] weight norms, users: 36.71154022216797, items: 39.949886322021484\n",
      "[it 5000] metrics (emb_loss, net_loss, reg, target): (0.48835003, 0.69215232, 4.9324627, 0.51301235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6021/10000 [00:43<00:26, 151.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:6000\n",
      "alpha:0.6\n",
      "beta:0.40000000000000013\n",
      "[it 6000] weight norms, users: 37.57398223876953, items: 41.457584381103516\n",
      "[it 6000] metrics (emb_loss, net_loss, reg, target): (0.46379268, 0.68232596, 5.3138924, 0.49036214)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7027/10000 [00:49<00:19, 154.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:7000\n",
      "alpha:0.7\n",
      "beta:0.30000000000000016\n",
      "[it 7000] weight norms, users: 38.207462310791016, items: 42.80542755126953\n",
      "[it 7000] metrics (emb_loss, net_loss, reg, target): (0.4492594, 0.68830723, 5.3273468, 0.47589612)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8017/10000 [00:58<00:14, 139.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:8000\n",
      "alpha:0.7999999999999999\n",
      "beta:0.20000000000000015\n",
      "[it 8000] weight norms, users: 38.699920654296875, items: 44.10477828979492\n",
      "[it 8000] metrics (emb_loss, net_loss, reg, target): (0.45737207, 0.68202066, 5.3895392, 0.48431978)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9033/10000 [01:05<00:06, 159.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:9000\n",
      "alpha:0.8999999999999999\n",
      "beta:0.10000000000000014\n",
      "[it 9000] weight norms, users: 39.09944152832031, items: 45.299373626708984\n",
      "[it 9000] metrics (emb_loss, net_loss, reg, target): (0.44907317, 0.69325233, 5.701674, 0.47758153)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:11<00:00, 139.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import letor_metrics\n",
    "import pyximport\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "pyximport.install()\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "raw_data_train = np.loadtxt('/data/recnet_draft/ml100k/train_all_raw.csv', skiprows = 1, delimiter=',')\n",
    "raw_data_test = np.loadtxt('/data/recnet_draft/ml100k/test_all_raw.csv', skiprows = 1, delimiter=',')\n",
    "raw_data = np.concatenate((raw_data_train, raw_data_test))\n",
    "from dataset_tt_static import TripletsDataset\n",
    "\n",
    "ds = TripletsDataset(raw_data_train, raw_data_test, threshold_user=60, rnd_seed=42)\n",
    "ds.train_test_split()\n",
    "\n",
    "ds.init_cached_random()\n",
    "import tensorflow as tf\n",
    "import bprnn_ml100k_param_tune_all\n",
    "import imp\n",
    "\n",
    "N_USERS = int(max(raw_data[:, 0])) + 1\n",
    "N_ITEMS = int(max(raw_data[:, 1])) + 1\n",
    "N_EMBEDDINGS = 2\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "imp.reload(bprnn_ml100k_param_tune_all)\n",
    "\n",
    "#%%\n",
    "def inner_network(user_emb, item_emb):\n",
    "    joined_input = tf.concat([user_emb, item_emb], 1)\n",
    "    net = slim.fully_connected(inputs=joined_input, num_outputs=16, activation_fn=tf.nn.relu)\n",
    "#     net = slim.fully_connected(inputs=joined_input, num_outputs=64, activation_fn=tf.nn.relu)\n",
    "#     net = slim.dro\n",
    "    net = slim.fully_connected(inputs=net, num_outputs=1, activation_fn=None)\n",
    "    return net\n",
    "\n",
    "model = bprnn_ml100k_param_tune_all.BPR_NN(N_USERS, N_ITEMS, N_EMBEDDINGS, alpha=0, beta=1, alpha_reg=0.005, inner_net=inner_network)\n",
    "model.build_graph()\n",
    "model.initialize_session()\n",
    "\n",
    "losses = []\n",
    "batch_size = 512\n",
    "for n_batches, cur_optim in [(10000, model.trainer_3)]:\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        if i%1000==0 and i/1000 >= 1:\n",
    "            model.alpha = model.alpha + 0.1\n",
    "            model.beta = model.beta - 0.1\n",
    "            print('batch number:'+str(i))\n",
    "            print('alpha:'+ str(model.alpha))\n",
    "            print('beta:'+ str(model.beta))\n",
    "        batch = ds.sample_train_batch(n_samples=batch_size)\n",
    "        fd = {\n",
    "            model.user_ids:  batch['users'], \n",
    "            model.left_ids:  batch['left_items'],\n",
    "            model.right_ids: batch['right_items'],\n",
    "            model.target_y:  batch['y'],\n",
    "        }\n",
    "        el, nl, reg, t, _ = model.session.run(\n",
    "            [model.embedding_loss, model.net_loss, model.regularization, model.target, cur_optim], \n",
    "            feed_dict=fd\n",
    "        )\n",
    "        losses.append((el, nl, reg, t))\n",
    "        if i%1000==0:\n",
    "            user_norm = np.linalg.norm(model.weights_u)\n",
    "            item_norm = np.linalg.norm(model.weights_i)\n",
    "            print('[it {}] weight norms, users: {}, items: {}'.format(i, user_norm, item_norm))\n",
    "            print('[it {}] metrics (emb_loss, net_loss, reg, target): {}'.format(i, losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction: 100%|██████████| 408/408 [00:00<00:00, 3532.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87564587272673344, 0.5730249097309823, 0.48993086854170803, nan, 1.0, 0.8896955117809705, 0.69693835499843326, 0.8611375561264456, 0.63092975357145753, 0.57064171895532012, 0.9284591831945489, 1.0, 0.0, 0.33333333333333331, 0.53418194731807067, 0.70580751486785287, 0.63092975357145753, 1.0, 0.53072127397724345, 0.76063956823570356, 0.90602543553468229, 0.51006913145829202, 0.84551932527972595, 0.77561996045262482, 0.59123520482302772, 0.88545988157148736, 0.62818704803510339, nan, 1.0, 0.99634880215493538, 0.07336392209936006, 0.85123609415942747, 1.0, 0.79358406776491097, 1.0, 0.97474295285678791, 1.0, 0.80481099920933907, 0.61410696267909359, 1.0, 1.0, 0.92493723314230458, 1.0, 0.29155904987671011, nan, 0.98483309595535218, nan, nan, 0.63092975357145753, 0.69947390308139201, 0.92663607790063995, 0.5184650094568698, 1.0, 1.0, 0.38685280723454163, 0.91972078914818756, 1.0, 0.57064171895532012, 1.0, 1.0, 0.94415922634006066, nan, nan, 1.0, 0.96746798348916929, 0.88995411685096004, 0.96746798348916929, 1.0, 0.74863614934104372, 0.83187246372888257, 1.0, 0.087471714101408207, 1.0, 0.7461976723150332, 1.0, 0.4283650469300963, 0.98289208195668787, 0.93056877806322291, nan, nan, 1.0, 0.93056877806322291, 1.0, 0.83645861337970373, nan, 0.90602543553468229, 0.85798094282237303, 1.0, 0.57064171895532012, 0.65092092980713256]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "export_basename = '/data/recnet_draft/ml100k/inc_alpha/vectors/'\n",
    "export_pred = open(export_basename + 'pr_ml100k_10', 'w')\n",
    "export_true = open(export_basename + 'gt_ml100k_10', 'w')\n",
    "\n",
    "ndcg_vals = []\n",
    "for u in tqdm(ds.data_keys, desc='Prediction', leave=True):\n",
    "    # if not u in ds.test:\n",
    "    if not u in ds.test or not ds.test[u]:\n",
    "        continue\n",
    "    response = np.zeros(len(ds.test[u]))\n",
    "    fd = {\n",
    "            model.user_ids:  (np.ones(len(ds.test[u]))*u).astype(np.int32), \n",
    "            model.left_ids:  np.array([i for (i, r) in ds.test[u]]).astype(np.int32),\n",
    "        }\n",
    "    response += model.session.run(model.embedding_left, feed_dict=fd)[:, 0]\n",
    "    response += model.session.run(model.left_output, feed_dict=fd)[:, 0]\n",
    "\n",
    "    # make relevances\n",
    "    relevances = np.array([r for (i, r) in ds.test[u]])\n",
    "    items = np.array([i for (i, r) in ds.test[u]])  # it's already sorted by true relevance\n",
    "    itemsGroundTruth = np.array([i for (i,r) in ds.test[u] if r == 1])\n",
    "    predicted_ranking = np.argsort(-response)\n",
    "\n",
    "    # write down predictions\n",
    "    export_pred.write(' '.join(map(str, [u] + list(items[predicted_ranking]))) + '\\n')\n",
    "    export_true.write(' '.join(map(str, [u] + list(itemsGroundTruth))) + '\\n')\n",
    "\n",
    "    # calc score\n",
    "    gain = letor_metrics.ndcg_from_ranking(relevances, predicted_ranking, 10)\n",
    "    ndcg_vals.append(gain)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "print(ndcg_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ints = [100, 500, 1000, 2000, 5000, 10000]\n",
    "pos = 1\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2)\n",
    "#ax[-1, -1].axis('off')\n",
    "\n",
    "for int in ints:\n",
    "    axis = plt.subplot(3, 2, pos)\n",
    "    axis.plot([x[0] for x in losses[:int]], c='b', label='embedding_loss')\n",
    "    grid()\n",
    "    legend()\n",
    "    xlabel('n_batches')\n",
    "    ylabel('embedding loss')\n",
    "    yscale('log')\n",
    "    draw()\n",
    "    show(block=False)\n",
    "    pos = pos + 1\n",
    "    fig.savefig('/home/sumit/recnet_draft/plots/ml100k/embedding_loss_dec_alpha.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ints = [100, 500, 1000, 2000, 5000, 10000]\n",
    "pos = 1\n",
    "fig, ax = plt.subplots(nrows=3, ncols=2)\n",
    "\n",
    "for int in ints:\n",
    "    axis = plt.subplot(3, 2, pos)\n",
    "    axis.plot([x[1] for x in losses[:int]], c='m', label='ranking_loss')\n",
    "    grid()\n",
    "    legend()\n",
    "    xlabel('n_batches')\n",
    "    ylabel('logloss')\n",
    "    yscale('log')\n",
    "    draw()\n",
    "    show(block=False)\n",
    "    pos = pos + 1\n",
    "    fig.savefig('/home/sumit/recnet_draft/plots/ml100k/ranking_loss_dec_alpha.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ints = [100, 500, 1000, 2000, 5000, 10000]\n",
    "pos = 1\n",
    "fig, ax = plt.subplots(nrows=3, ncols=2)\n",
    "for int in ints:\n",
    "    axis = plt.subplot(3, 2, pos)\n",
    "    axis.plot([x[3] for x in losses[: int]], c='g', label='target')\n",
    "    grid()\n",
    "    legend()\n",
    "    xlabel('n_batches')\n",
    "    ylabel('recnet loss')\n",
    "    #yscale('log')\n",
    "    draw()\n",
    "    show(block=False)\n",
    "    pos = pos + 1\n",
    "    fig.savefig('/home/sumit/recnet_draft/plots/ml100k/target_loss_dec_alpha')\n",
    "plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
