{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Split users:  10%|▉         | 40/408 [00:00<00:01, 184.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: random seed is None, default class seed (42) will be used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/1000 [00:00<01:52,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[it 0] weight norms, users: 73.19390106201172, items: 96.90826416015625\n",
      "[it 0] metrics (emb_loss, net_loss, reg, target): (0.81928563, 0.69419539, 17.036283, 0.69589901)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 518/1000 [00:03<00:03, 144.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[it 500] weight norms, users: 73.34114837646484, items: 97.07215118408203\n",
      "[it 500] metrics (emb_loss, net_loss, reg, target): (0.69822323, 0.49626598, 17.217907, 0.49798778)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 144.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import letor_metrics\n",
    "import pyximport\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "pyximport.install()\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "raw_data_train = np.loadtxt('/data/recnet_draft/ml100k/train_all_raw.csv', skiprows = 1, delimiter=',')\n",
    "raw_data_test = np.loadtxt('/data/recnet_draft/ml100k/test_all_raw.csv', skiprows = 1, delimiter=',')\n",
    "raw_data = np.concatenate((raw_data_train, raw_data_test))\n",
    "from dataset_tt_static import TripletsDataset\n",
    "\n",
    "ds = TripletsDataset(raw_data_train, raw_data_test, threshold_user=60, rnd_seed=42)\n",
    "ds.train_test_split()\n",
    "\n",
    "ds.init_cached_random()\n",
    "import tensorflow as tf\n",
    "import bprnn_ml100k_param_tune_all\n",
    "import imp\n",
    "\n",
    "N_USERS = int(max(raw_data[:, 0])) + 1\n",
    "N_ITEMS = int(max(raw_data[:, 1])) + 1\n",
    "N_EMBEDDINGS = 17\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "imp.reload(bprnn_ml100k_param_tune_all)\n",
    "\n",
    "#%%\n",
    "def inner_network(user_emb, item_emb):\n",
    "    joined_input = tf.concat([user_emb, item_emb], 1)\n",
    "    net = slim.fully_connected(inputs=joined_input, num_outputs=32, activation_fn=tf.nn.relu)\n",
    "#     net = slim.fully_connected(inputs=joined_input, num_outputs=64, activation_fn=tf.nn.relu)\n",
    "#     net = slim.dro\n",
    "    net = slim.fully_connected(inputs=net, num_outputs=1, activation_fn=None)\n",
    "    return net\n",
    "\n",
    "model = bprnn_ml100k_param_tune_all.BPR_NN(N_USERS, N_ITEMS, N_EMBEDDINGS, alpha=1, beta=0, alpha_reg=0.0001, inner_net=inner_network)\n",
    "model.build_graph()\n",
    "model.initialize_session()\n",
    "\n",
    "losses = []\n",
    "batch_size = 512\n",
    "for n_batches, cur_optim in [(1000, model.trainer_3)]:\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        batch = ds.sample_train_batch(n_samples=batch_size)\n",
    "        fd = {\n",
    "            model.user_ids:  batch['users'], \n",
    "            model.left_ids:  batch['left_items'],\n",
    "            model.right_ids: batch['right_items'],\n",
    "            model.target_y:  batch['y'],\n",
    "        }\n",
    "        el, nl, reg, t, _ = model.session.run(\n",
    "            [model.embedding_loss, model.net_loss, model.regularization, model.target, cur_optim], \n",
    "            feed_dict=fd\n",
    "        )\n",
    "        losses.append((el, nl, reg, t))\n",
    "        if i%500==0:\n",
    "            user_norm = np.linalg.norm(model.weights_u)\n",
    "            item_norm = np.linalg.norm(model.weights_i)\n",
    "            print('[it {}] weight norms, users: {}, items: {}'.format(i, user_norm, item_norm))\n",
    "            print('[it {}] metrics (emb_loss, net_loss, reg, target): {}'.format(i, losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction: 100%|██████████| 408/408 [00:00<00:00, 2957.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.49125969208957582, 0.85123609415942747, nan, 1.0, 0.94039623903753067, 0.68120607411527379, 0.80481099920933907, 1.0, 0.65092092980713256, 1.0, 1.0, 0.69342640361727081, 0.43067655807339306, 0.65023152450395871, 0.64575457684945847, 0.63092975357145753, 1.0, 0.88545988157148736, 0.76063956823570356, 0.96746798348916929, 0.44202197604759996, 0.78873683487098878, 0.61686884000658904, 0.65092092980713256, 1.0, 0.5107574098602351, nan, 1.0, 0.98880260418802413, 0.22119341301481268, 0.61179523735681218, 1.0, 1.0, 1.0, 0.90682503796496661, 1.0, 0.93637921180104833, 0.64312114159402101, 0.7506372960520511, 1.0, 0.93268881912509716, 1.0, 0.52710649664054565, nan, 0.97149772446444627, nan, nan, 0.63092975357145753, 0.39215784798408643, 1.0, 0.39401519638101345, 0.93056877806322291, 1.0, 0.43067655807339306, 1.0, 1.0, 0.65092092980713256, 1.0, 1.0, 0.94956626441686443, nan, nan, 1.0, 1.0, 0.78854972088559572, 1.0, 1.0, 0.90682503796496661, 0.83187246372888257, 1.0, 0.29178833734520582, 1.0, 1.0, 1.0, 0.5926825204089029, 0.98289208195668787, 0.9216017310213247, nan, nan, 1.0, 1.0, 1.0, 1.0, nan, 1.0, 0.9216017310213247, 0.93374577654561108, 0.65092092980713256, 0.91972078914818756]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "export_basename = '/data/recnet_draft/ml100k/vectors/'\n",
    "export_pred = open(export_basename + 'pr_ml100k_10', 'w')\n",
    "export_true = open(export_basename + 'gt_ml100k_10', 'w')\n",
    "\n",
    "ndcg_vals = []\n",
    "for u in tqdm(ds.data_keys, desc='Prediction', leave=True):\n",
    "    # if not u in ds.test:\n",
    "    if not u in ds.test or not ds.test[u]:\n",
    "        continue\n",
    "    response = np.zeros(len(ds.test[u]))\n",
    "    fd = {\n",
    "            model.user_ids:  (np.ones(len(ds.test[u]))*u).astype(np.int32), \n",
    "            model.left_ids:  np.array([i for (i, r) in ds.test[u]]).astype(np.int32),\n",
    "        }\n",
    "    response += model.session.run(model.embedding_left, feed_dict=fd)[:, 0]\n",
    "    response += model.session.run(model.left_output, feed_dict=fd)[:, 0]\n",
    "\n",
    "    # make relevances\n",
    "    relevances = np.array([r for (i, r) in ds.test[u]])\n",
    "    items = np.array([i for (i, r) in ds.test[u]])  # it's already sorted by true relevance\n",
    "    itemsGroundTruth = np.array([i for (i,r) in ds.test[u] if r == 1])\n",
    "    predicted_ranking = np.argsort(-response)\n",
    "\n",
    "    # write down predictions\n",
    "    export_pred.write(' '.join(map(str, [u] + list(items[predicted_ranking]))) + '\\n')\n",
    "    export_true.write(' '.join(map(str, [u] + list(itemsGroundTruth))) + '\\n')\n",
    "\n",
    "    # calc score\n",
    "    gain = letor_metrics.ndcg_from_ranking(relevances, predicted_ranking, 10)\n",
    "    ndcg_vals.append(gain)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "print(ndcg_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prediction: 100%|██████████| 408/408 [00:00<00:00, 25366.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[242 171 111 256]\n",
      "[909 186 694 362 896]\n",
      "[181 302  12  23 923 174 654 519 195 498  81 921 530 427 588  96 603 517\n",
      "  32 492 172 509 507 191 525 474 213  50 269]\n",
      "[]\n",
      "[354 124 316]\n",
      "[ 272  340  346  313 1016  307  298]\n",
      "[ 381   70  255 1101  311  199  168  491  249  240  367  191]\n",
      "[ 313  310  431  516   11   22  187  181   64  173  515  174  568  156   56\n",
      "    7  176  496  318   98  209  199  186   95  194   96  435  234  429  203\n",
      "  190   87   28  520  132  135  195   50  183  215   79  154    8  196  182\n",
      "    9   12  202  475  238  425  143  434  588  172   69  746   70  463  736\n",
      "  633  168  184  655  718  732  160  211   31  662  447  175  228  179   81\n",
      "  229  185  141  423  188  436  367   10  222   91  511  778  389 1141  919\n",
      "  582  959  403  111 1133  230   72  284  684  636  237  503  591  235  216\n",
      "  191  651]\n",
      "[298]\n",
      "[272 182]\n",
      "[246 993 250 268 307]\n",
      "[ 616  193   47   58 1073  686  176  642  208  508   61  657  589  813   76\n",
      "  132  655  789  357  647  693  183  518  631   86  484   50  228  969   52\n",
      "  469  736  433  587 1010  192   92  211  652    4  238  318   98  223  629\n",
      "   31  420  204  961   97  636  741   53  201  168  421  200  603  111  525\n",
      "  443  196  744  410 1223  735  549  219  447  404  684   71  506  501  471\n",
      "  746  241  431  151  942  559 1153   82 1045  436   32  465  265  160  109\n",
      "   91  470  679  537  215   49 1011  581  692  715  186  458 1219  386  685\n",
      "   68   54  727 1211 1118  274 1218   70 1044 1058  143  217 1135  356  401\n",
      " 1048 1110  399  206 1009  824  448  235  625  372  997 1119  402  367  737\n",
      "  451  293  258  246 1226 1012  286  257 1014  250   93 1007  993  248  696\n",
      "  268  313  347  343  338   56  157  428  214  921  156  651  959  390  153\n",
      "  170  346  750  302  690]\n",
      "[175 202]\n",
      "[344]\n",
      "[354 299 316   9 451 995]\n",
      "[258 751 294 300 289 520 190 485  50 498  22  87 195 222 945 202 435 367\n",
      " 999  73 451 116  72 239 290 756 790 585  90 401  67  80  94 158]\n",
      "[354]\n",
      "[313 272]\n",
      "[333 258 259]\n",
      "[286 293 709 238]\n",
      "[354 302 342]\n",
      "[ 689  306  887  330  148 1253  257  147  988  546  477  177  332  829   98]\n",
      "[ 310    1 1168  177  182  276  187  127  366]\n",
      "[  14  387 1418  591  421]\n",
      "[866 831]\n",
      "[242 316 302]\n",
      "[302 751  73 722 167  94]\n",
      "[]\n",
      "[313 269]\n",
      "[331 902  14 737 303 315 262 316]\n",
      "[  92 1499  652  201  710 1052  363  184 1228  397  410  319  238  153 1288\n",
      "  364    7  778  436 1059  474  108  434  586 1047  230  269]\n",
      "[ 354  316  315  348  537 1375  143  172  224  710  465  404  431  179  419\n",
      " 1074 1060]\n",
      "[603 483  79 520 902]\n",
      "[ 936  302  173  170  487  965  198  202  433  510  606  641  962   91  418\n",
      "  543  165  730  166  512   86  855  702 1056  747  216  778  732  517 1119\n",
      "  955   49  746  210 1103  204  792  516  715  396   81  333]\n",
      "[313 344]\n",
      "[350 326 342 302 728]\n",
      "[ 301  288  285  132    8  276  496  191   96  715   87  955  509  316 1007\n",
      "  246  127 1142  251  248  297  255  298 1014]\n",
      "[302 272  87 596 582 300 133 896 289 435 736 715 313 269 703]\n",
      "[ 137  529    7  168 1113  393  577  496  188  701]\n",
      "[ 354  333  316 1063  483  568  710   28  787   87  317  470  480  625  684\n",
      "  808  241  143   42  497   54  136   27  622   97  463  392  184  732   95\n",
      "  479  953    4   96  494   55  747  630  651  239  399  227  578  394  761\n",
      "  944  569   41 1055  836   62  781  686  139  941  842  627  366   29  554\n",
      " 1409 1219   68   49  790  376   72  415  794  999  142   38  810 1249  780\n",
      "  386  775  577  373   94  769  572  774  398 1531 1044  303  302]\n",
      "[313 345 302 268 896 109 273 346]\n",
      "[288 286 250 223 315  73 313   7]\n",
      "[ 708  331  972  564  419  477  469  274  284 1133  775   96 1540   49  781\n",
      "  710   77 1020  966    1  275   87  692  603    8 1426  614   12  223  531\n",
      "  277  496  367    9  500  607  451  402   13  136  763  625  812  924   22\n",
      "   31  403  148   24  239  147  727   28   50  144  156  591  100  699  155\n",
      "  462   51  729  739  378   64  168  747   56  286   54  107   58  117   65\n",
      "  794  293 1262  356  427 1058   66  181  191   70  281  385  655  200 1074\n",
      "  126  197  576  248 1221  204  959  732  659  660  251  295  684   81   79\n",
      "  213  686  746   83  319  216  317   82  392 1016  232  468  443  318 1286\n",
      "   97  258  676  735  328  234   98  215  588  121  873  471  405  357  265\n",
      "  283  172  241  125  301  476  282  288  127  479  174 1189  178  480 1007\n",
      "  501  143  210  627  421  150  506  211  326  509  255  164  515  194  183\n",
      "  173  690  302  936  187  750  195  754  196  199 1119  657  310  520  339\n",
      "  304  526  658  313  345  209  272  354  942  347  755]\n",
      "[ 895  346  340  272 1434  269  307  347  334  271  358  327  301  316  529\n",
      "  474  204  943  168  198]\n",
      "[]\n",
      "[904 316 902 936 354 749 245]\n",
      "[]\n",
      "[]\n",
      "[307]\n",
      "[ 313 1377  257  250  301  311  751  887  880  127   50]\n",
      "[ 323  338  552    1  362   67   69  271  343  895  313  751    3  385 1074\n",
      "   11  569  568    2 1239  358  265  576  578  366  367   79  258   22  386\n",
      "    7  760   12   68  541  475  318   82  423   72   24  255  168  597  400\n",
      "   28  549  172   94  402   91   90]\n",
      "[188 568 447 143 381  15 393 843 137 616 340 255 739]\n",
      "[510 250 879 431 153 210  69 136 135 655  22 732 468 651  51 318 392  97\n",
      " 692 173 211  70 168 239  56 204 216 451   4 746 202  88  73 186 778 150\n",
      " 176 174 172  89 144  79 183  96 195 228 226 550 684   2 385 566 230 233\n",
      " 161  82 265 229 227 823 720  38 399 554 472 449 665  98 234 143 427 423\n",
      "  87 588  95 699 419 625 755  94 560 141 197]\n",
      "[902]\n",
      "[298]\n",
      "[900 778]\n",
      "[125 409]\n",
      "[873 568]\n",
      "[313]\n",
      "[ 331  269  186  168  427  161  164  151   77  357  477  925  431  685 1189\n",
      "   82  676  195  568  754  241  229  226  339  470  562  298  559  636  520\n",
      "  655  204  136  403  763   87  215  840   22   24  483   96 1226  304   95\n",
      "  132  228  203   66  230  576  402    1  739  100  117  472  591  658    2\n",
      "  404  692  107   97 1119  125  282    8  526  588    7    4   99  284  746\n",
      "   98  127  216    9  318  367  277 1011  480  603   11  496   12  468  485\n",
      "  531  491]\n",
      "[936  71 236 125 303 297]\n",
      "[]\n",
      "[]\n",
      "[313 531]\n",
      "[270 268 333]\n",
      "[242 310 262 269 347 305 750 316 905 312]\n",
      "[315 272 269]\n",
      "[691]\n",
      "[245 993 845 862 815]\n",
      "[313 657 272 245]\n",
      "[269]\n",
      "[316 638 427 739 517 137]\n",
      "[272]\n",
      "[340 269 270]\n",
      "[ 900 1024  902]\n",
      "[ 751  313  304  690  300  457  873  258  326  748  289  319 1152  866  237\n",
      "  934  222  508 1051  151  150  148  147  845 1117  284  126]\n",
      "[301 313 909 316]\n",
      "[603  69  82 183 385 169 176   1 205 144 135 527 193 164  89  96  50 180\n",
      " 318 210 313 199 651 127 969 265 177 136]\n",
      "[]\n",
      "[]\n",
      "[286]\n",
      "[ 313  286  427  705    1  151  276  475 1067  408  189   86  319  275  124]\n",
      "[354]\n",
      "[ 262 1280  303  327  336  333 1105  690   50  347  272  310  273  527  591\n",
      " 1016  127  318 1143]\n",
      "[]\n",
      "[286 333 257]\n",
      "[  70  354  649  192    1  218   64   83  276  100  193   87  425 1098  272]\n",
      "[ 272  269  307  316  268  346  315  748  329  347  902  876  348  881  260\n",
      "  299  246  248  295  287  992 1014  746  762  815]\n",
      "[1592  904]\n",
      "[354 316]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ndcg_vals = []\n",
    "for u in tqdm(ds.data_keys, desc='Prediction', leave=True):\n",
    "    # if not u in ds.test:\n",
    "    if not u in ds.test or not ds.test[u]:\n",
    "        continue\n",
    "    arr = np.array([i for (i,r) in ds.test[u] if r == 1])\n",
    "    print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
